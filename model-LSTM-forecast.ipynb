{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treino = pd.read_csv('./data/mini_inidice_RL1.csv')\n",
    "base_teste = pd.read_csv('./data/mini_indice_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>125330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Data  Fechamento\n",
       "0    2021-07-08      125700\n",
       "1    2021-07-08      125725\n",
       "2    2021-07-08      125790\n",
       "3    2021-07-08      125800\n",
       "4    2021-07-08      125795\n",
       "..          ...         ...\n",
       "528  2021-07-08      125185\n",
       "529  2021-07-08      125105\n",
       "530  2021-07-08      125125\n",
       "531  2021-07-08      125240\n",
       "532  2021-07-08      125330\n",
       "\n",
       "[533 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125700],\n",
       "       [125725],\n",
       "       [125790],\n",
       "       [125800],\n",
       "       [125795],\n",
       "       [125785],\n",
       "       [125860],\n",
       "       [125840],\n",
       "       [125805],\n",
       "       [125825],\n",
       "       [125805],\n",
       "       [125805],\n",
       "       [125850],\n",
       "       [125805],\n",
       "       [125805],\n",
       "       [125835],\n",
       "       [125835],\n",
       "       [125830],\n",
       "       [125810],\n",
       "       [125790],\n",
       "       [125800],\n",
       "       [125870],\n",
       "       [125835],\n",
       "       [125815],\n",
       "       [125830],\n",
       "       [125785],\n",
       "       [125835],\n",
       "       [125820],\n",
       "       [125825],\n",
       "       [125830],\n",
       "       [125775],\n",
       "       [125755],\n",
       "       [125730],\n",
       "       [125805],\n",
       "       [125850],\n",
       "       [125835],\n",
       "       [125875],\n",
       "       [125870],\n",
       "       [125855],\n",
       "       [125840],\n",
       "       [125805],\n",
       "       [125780],\n",
       "       [125765],\n",
       "       [125775],\n",
       "       [125725],\n",
       "       [125695],\n",
       "       [125730],\n",
       "       [125770],\n",
       "       [125740],\n",
       "       [125735],\n",
       "       [125785],\n",
       "       [125785],\n",
       "       [125810],\n",
       "       [125850],\n",
       "       [125875],\n",
       "       [125855],\n",
       "       [125910],\n",
       "       [125785],\n",
       "       [125835],\n",
       "       [125860],\n",
       "       [125875],\n",
       "       [125805],\n",
       "       [125810],\n",
       "       [125750],\n",
       "       [125685],\n",
       "       [125615],\n",
       "       [125590],\n",
       "       [125595],\n",
       "       [125560],\n",
       "       [125605],\n",
       "       [125600],\n",
       "       [125550],\n",
       "       [125545],\n",
       "       [125615],\n",
       "       [125705],\n",
       "       [125695],\n",
       "       [125770],\n",
       "       [125830],\n",
       "       [125845],\n",
       "       [125855],\n",
       "       [125790],\n",
       "       [125735],\n",
       "       [125755],\n",
       "       [125715],\n",
       "       [125775],\n",
       "       [125770],\n",
       "       [125755],\n",
       "       [125750],\n",
       "       [125735],\n",
       "       [125725],\n",
       "       [125705],\n",
       "       [125690],\n",
       "       [125655],\n",
       "       [125635],\n",
       "       [125615],\n",
       "       [125555],\n",
       "       [125455],\n",
       "       [125400],\n",
       "       [125405],\n",
       "       [125390],\n",
       "       [125410],\n",
       "       [125400],\n",
       "       [125445],\n",
       "       [125635],\n",
       "       [125730],\n",
       "       [125710],\n",
       "       [125645],\n",
       "       [125710],\n",
       "       [125750],\n",
       "       [125730],\n",
       "       [125770],\n",
       "       [125805],\n",
       "       [125805],\n",
       "       [125835],\n",
       "       [125810],\n",
       "       [125785],\n",
       "       [125700],\n",
       "       [125700],\n",
       "       [125675],\n",
       "       [125645],\n",
       "       [125595],\n",
       "       [125625],\n",
       "       [125605],\n",
       "       [125645],\n",
       "       [125670],\n",
       "       [125665],\n",
       "       [125755],\n",
       "       [125790],\n",
       "       [125850],\n",
       "       [125825],\n",
       "       [125825],\n",
       "       [125815],\n",
       "       [125835],\n",
       "       [125770],\n",
       "       [125740],\n",
       "       [125755],\n",
       "       [125730],\n",
       "       [125710],\n",
       "       [125700],\n",
       "       [125685],\n",
       "       [125690],\n",
       "       [125645],\n",
       "       [125655],\n",
       "       [125660],\n",
       "       [125580],\n",
       "       [125515],\n",
       "       [125565],\n",
       "       [125570],\n",
       "       [125625],\n",
       "       [125570],\n",
       "       [125520],\n",
       "       [125520],\n",
       "       [125490],\n",
       "       [125480],\n",
       "       [125450],\n",
       "       [125395],\n",
       "       [125360],\n",
       "       [125295],\n",
       "       [125290],\n",
       "       [125360],\n",
       "       [125420],\n",
       "       [125435],\n",
       "       [125460],\n",
       "       [125465],\n",
       "       [125510],\n",
       "       [125520],\n",
       "       [125490],\n",
       "       [125495],\n",
       "       [125485],\n",
       "       [125580],\n",
       "       [125640],\n",
       "       [125615],\n",
       "       [125645],\n",
       "       [125640],\n",
       "       [125685],\n",
       "       [125810],\n",
       "       [125800],\n",
       "       [125780],\n",
       "       [125735],\n",
       "       [125625],\n",
       "       [125770],\n",
       "       [125750],\n",
       "       [125830],\n",
       "       [125925],\n",
       "       [125935],\n",
       "       [125925],\n",
       "       [125905],\n",
       "       [125980],\n",
       "       [126045],\n",
       "       [126020],\n",
       "       [126040],\n",
       "       [126025],\n",
       "       [126030],\n",
       "       [126075],\n",
       "       [126070],\n",
       "       [126035],\n",
       "       [126035],\n",
       "       [125990],\n",
       "       [125940],\n",
       "       [126050],\n",
       "       [126070],\n",
       "       [126085],\n",
       "       [126020],\n",
       "       [125970],\n",
       "       [125900],\n",
       "       [125885],\n",
       "       [125970],\n",
       "       [126130],\n",
       "       [126155],\n",
       "       [126170],\n",
       "       [126200],\n",
       "       [126150],\n",
       "       [126240],\n",
       "       [126245],\n",
       "       [126235],\n",
       "       [126180],\n",
       "       [126195],\n",
       "       [126250],\n",
       "       [126215],\n",
       "       [126165],\n",
       "       [126190],\n",
       "       [126230],\n",
       "       [126270],\n",
       "       [126275],\n",
       "       [126335],\n",
       "       [126350],\n",
       "       [126380],\n",
       "       [126390],\n",
       "       [126345],\n",
       "       [126400],\n",
       "       [126220],\n",
       "       [126140],\n",
       "       [126155],\n",
       "       [126125],\n",
       "       [126120],\n",
       "       [126175],\n",
       "       [126180],\n",
       "       [126190],\n",
       "       [126230],\n",
       "       [126215],\n",
       "       [126195],\n",
       "       [126120],\n",
       "       [126130],\n",
       "       [126205],\n",
       "       [126150],\n",
       "       [126185],\n",
       "       [126205],\n",
       "       [126195],\n",
       "       [126150],\n",
       "       [126165],\n",
       "       [126110],\n",
       "       [126170],\n",
       "       [126120],\n",
       "       [126065],\n",
       "       [126040],\n",
       "       [126075],\n",
       "       [126100],\n",
       "       [126225],\n",
       "       [126165],\n",
       "       [126105],\n",
       "       [126000],\n",
       "       [125965],\n",
       "       [125970],\n",
       "       [126020],\n",
       "       [126010],\n",
       "       [126040],\n",
       "       [126055],\n",
       "       [126065],\n",
       "       [126065],\n",
       "       [126075],\n",
       "       [126105],\n",
       "       [126050],\n",
       "       [126110],\n",
       "       [126090],\n",
       "       [126070],\n",
       "       [126025],\n",
       "       [126080],\n",
       "       [126065],\n",
       "       [126010],\n",
       "       [126090],\n",
       "       [126070],\n",
       "       [126060],\n",
       "       [126070],\n",
       "       [126070],\n",
       "       [126055],\n",
       "       [126090],\n",
       "       [126080],\n",
       "       [126075],\n",
       "       [126125],\n",
       "       [126085],\n",
       "       [126080],\n",
       "       [126090],\n",
       "       [126085],\n",
       "       [126160],\n",
       "       [126105],\n",
       "       [126160],\n",
       "       [126195],\n",
       "       [126130],\n",
       "       [126170],\n",
       "       [126140],\n",
       "       [126135],\n",
       "       [126145],\n",
       "       [126080],\n",
       "       [126105],\n",
       "       [126065],\n",
       "       [126040],\n",
       "       [126010],\n",
       "       [126010],\n",
       "       [125985],\n",
       "       [125930],\n",
       "       [125950],\n",
       "       [125920],\n",
       "       [125955],\n",
       "       [126035],\n",
       "       [126060],\n",
       "       [126125],\n",
       "       [126095],\n",
       "       [126105],\n",
       "       [126135],\n",
       "       [126225],\n",
       "       [126240],\n",
       "       [126165],\n",
       "       [126150],\n",
       "       [126100],\n",
       "       [126105],\n",
       "       [126235],\n",
       "       [126195],\n",
       "       [126105],\n",
       "       [126095],\n",
       "       [126135],\n",
       "       [126160],\n",
       "       [126185],\n",
       "       [126145],\n",
       "       [126005],\n",
       "       [125935],\n",
       "       [125860],\n",
       "       [125795],\n",
       "       [125815],\n",
       "       [125770],\n",
       "       [125770],\n",
       "       [125795],\n",
       "       [125885],\n",
       "       [125915],\n",
       "       [125895],\n",
       "       [125810],\n",
       "       [125815],\n",
       "       [125800],\n",
       "       [125785],\n",
       "       [125830],\n",
       "       [125845],\n",
       "       [125675],\n",
       "       [125610],\n",
       "       [125545],\n",
       "       [125545],\n",
       "       [125470],\n",
       "       [125380],\n",
       "       [125305],\n",
       "       [125305],\n",
       "       [125355],\n",
       "       [125330],\n",
       "       [125245],\n",
       "       [125210],\n",
       "       [125230],\n",
       "       [125165],\n",
       "       [125140],\n",
       "       [125090],\n",
       "       [125105],\n",
       "       [125120],\n",
       "       [125175],\n",
       "       [125235],\n",
       "       [125330],\n",
       "       [125265],\n",
       "       [125120],\n",
       "       [125020],\n",
       "       [125180],\n",
       "       [125225],\n",
       "       [125080],\n",
       "       [124980],\n",
       "       [125045],\n",
       "       [125020],\n",
       "       [125010],\n",
       "       [125055],\n",
       "       [124995],\n",
       "       [125050],\n",
       "       [125130],\n",
       "       [125035],\n",
       "       [125065],\n",
       "       [125005],\n",
       "       [124865],\n",
       "       [124845],\n",
       "       [124820],\n",
       "       [124830],\n",
       "       [124770],\n",
       "       [124830],\n",
       "       [124860],\n",
       "       [124965],\n",
       "       [125105],\n",
       "       [125135],\n",
       "       [125185],\n",
       "       [125155],\n",
       "       [125215],\n",
       "       [125155],\n",
       "       [125065],\n",
       "       [125070],\n",
       "       [125115],\n",
       "       [125075],\n",
       "       [125065],\n",
       "       [125160],\n",
       "       [125040],\n",
       "       [125105],\n",
       "       [125160],\n",
       "       [125235],\n",
       "       [125320],\n",
       "       [125185],\n",
       "       [125180],\n",
       "       [125250],\n",
       "       [125400],\n",
       "       [125380],\n",
       "       [125370],\n",
       "       [125385],\n",
       "       [125320],\n",
       "       [125450],\n",
       "       [125380],\n",
       "       [125430],\n",
       "       [125290],\n",
       "       [125165],\n",
       "       [125140],\n",
       "       [125090],\n",
       "       [125145],\n",
       "       [125120],\n",
       "       [125185],\n",
       "       [125250],\n",
       "       [125255],\n",
       "       [125280],\n",
       "       [125280],\n",
       "       [125400],\n",
       "       [125525],\n",
       "       [125480],\n",
       "       [125450],\n",
       "       [125575],\n",
       "       [125530],\n",
       "       [125575],\n",
       "       [125625],\n",
       "       [125700],\n",
       "       [125780],\n",
       "       [125740],\n",
       "       [125660],\n",
       "       [125695],\n",
       "       [125660],\n",
       "       [125660],\n",
       "       [125630],\n",
       "       [125615],\n",
       "       [125625],\n",
       "       [125510],\n",
       "       [125445],\n",
       "       [125450],\n",
       "       [125370],\n",
       "       [125240],\n",
       "       [125255],\n",
       "       [125350],\n",
       "       [125425],\n",
       "       [125395],\n",
       "       [125335],\n",
       "       [125335],\n",
       "       [125265],\n",
       "       [125260],\n",
       "       [125190],\n",
       "       [125170],\n",
       "       [125210],\n",
       "       [125265],\n",
       "       [125295],\n",
       "       [125275],\n",
       "       [125170],\n",
       "       [125160],\n",
       "       [125140],\n",
       "       [125170],\n",
       "       [125055],\n",
       "       [125135],\n",
       "       [125150],\n",
       "       [125170],\n",
       "       [125145],\n",
       "       [125195],\n",
       "       [125150],\n",
       "       [125210],\n",
       "       [125220],\n",
       "       [125210],\n",
       "       [125270],\n",
       "       [125230],\n",
       "       [125210],\n",
       "       [125215],\n",
       "       [125200],\n",
       "       [125190],\n",
       "       [125380],\n",
       "       [125375],\n",
       "       [125405],\n",
       "       [125460],\n",
       "       [125485],\n",
       "       [125450],\n",
       "       [125410],\n",
       "       [125325],\n",
       "       [125305],\n",
       "       [125320],\n",
       "       [125365],\n",
       "       [125380],\n",
       "       [125355],\n",
       "       [125395],\n",
       "       [125330],\n",
       "       [125365],\n",
       "       [125380],\n",
       "       [125455],\n",
       "       [125385],\n",
       "       [125370],\n",
       "       [125455],\n",
       "       [125395],\n",
       "       [125385],\n",
       "       [125375],\n",
       "       [125350],\n",
       "       [125250],\n",
       "       [125275],\n",
       "       [125195],\n",
       "       [125140],\n",
       "       [125035],\n",
       "       [125000],\n",
       "       [125065],\n",
       "       [124955],\n",
       "       [125045],\n",
       "       [125030],\n",
       "       [125090],\n",
       "       [125185],\n",
       "       [125105],\n",
       "       [125125],\n",
       "       [125240],\n",
       "       [125330]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino = base_treino.drop('Data', axis =1)\n",
    "treino.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste = base_teste.drop('Data', axis =1)\n",
    "#teste.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range = (0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento_normalizada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = []\n",
    "preco_real = []\n",
    "for i in range(32, 533):\n",
    "    previsores.append(base_treinamento_normalizada[i-32:i, 0])\n",
    "    preco_real.append(base_treinamento_normalizada[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores, preco_real = np.array(previsores), np.array(preco_real) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57055215, 0.58588957, 0.62576687, ..., 0.65030675, 0.61656442,\n",
       "        0.60429448],\n",
       "       [0.58588957, 0.62576687, 0.63190184, ..., 0.61656442, 0.60429448,\n",
       "        0.58895706],\n",
       "       [0.62576687, 0.63190184, 0.62883436, ..., 0.60429448, 0.58895706,\n",
       "        0.63496933],\n",
       "       ...,\n",
       "       [0.39263804, 0.3404908 , 0.32822086, ..., 0.19631902, 0.25460123,\n",
       "        0.20552147],\n",
       "       [0.3404908 , 0.32822086, 0.33742331, ..., 0.25460123, 0.20552147,\n",
       "        0.21779141],\n",
       "       [0.32822086, 0.33742331, 0.36503067, ..., 0.20552147, 0.21779141,\n",
       "        0.28834356]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = np.reshape(previsores, (previsores.shape[0], previsores.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, verbose=1)\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(filepath='pesos1.h5', monitor='loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0623 - mean_absolute_error: 0.1918\n",
      "Epoch 00001: loss improved from inf to 0.06098, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0610 - mean_absolute_error: 0.1899\n",
      "Epoch 2/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1429\n",
      "Epoch 00002: loss improved from 0.06098 to 0.03016, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0302 - mean_absolute_error: 0.1413\n",
      "Epoch 3/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1345\n",
      "Epoch 00003: loss improved from 0.03016 to 0.02862, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0286 - mean_absolute_error: 0.1343\n",
      "Epoch 4/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.1217\n",
      "Epoch 00004: loss improved from 0.02862 to 0.02339, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0234 - mean_absolute_error: 0.1211\n",
      "Epoch 5/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1338\n",
      "Epoch 00005: loss did not improve from 0.02339\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0270 - mean_absolute_error: 0.1315\n",
      "Epoch 6/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0236 - mean_absolute_error: 0.1227\n",
      "Epoch 00006: loss improved from 0.02339 to 0.02336, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0234 - mean_absolute_error: 0.1224\n",
      "Epoch 7/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.1194\n",
      "Epoch 00007: loss improved from 0.02336 to 0.02278, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0228 - mean_absolute_error: 0.1199\n",
      "Epoch 8/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0211 - mean_absolute_error: 0.1159\n",
      "Epoch 00008: loss improved from 0.02278 to 0.02056, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0206 - mean_absolute_error: 0.1139\n",
      "Epoch 9/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.1158\n",
      "Epoch 00009: loss improved from 0.02056 to 0.02052, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0205 - mean_absolute_error: 0.1152\n",
      "Epoch 10/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.1131\n",
      "Epoch 00010: loss improved from 0.02052 to 0.01926, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0193 - mean_absolute_error: 0.1130\n",
      "Epoch 11/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.1062\n",
      "Epoch 00011: loss improved from 0.01926 to 0.01816, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0182 - mean_absolute_error: 0.1061\n",
      "Epoch 12/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.1121\n",
      "Epoch 00012: loss did not improve from 0.01816\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0186 - mean_absolute_error: 0.1111\n",
      "Epoch 13/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0151 - mean_absolute_error: 0.1001\n",
      "Epoch 00013: loss improved from 0.01816 to 0.01543, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0154 - mean_absolute_error: 0.1014\n",
      "Epoch 14/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0976\n",
      "Epoch 00014: loss improved from 0.01543 to 0.01467, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0147 - mean_absolute_error: 0.0982\n",
      "Epoch 15/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0151 - mean_absolute_error: 0.1008\n",
      "Epoch 00015: loss did not improve from 0.01467\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0157 - mean_absolute_error: 0.1020\n",
      "Epoch 16/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0976\n",
      "Epoch 00016: loss did not improve from 0.01467\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0151 - mean_absolute_error: 0.0981\n",
      "Epoch 17/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0932\n",
      "Epoch 00017: loss improved from 0.01467 to 0.01351, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0135 - mean_absolute_error: 0.0940\n",
      "Epoch 18/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0152 - mean_absolute_error: 0.0985\n",
      "Epoch 00018: loss did not improve from 0.01351\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0151 - mean_absolute_error: 0.0987\n",
      "Epoch 19/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0977\n",
      "Epoch 00019: loss did not improve from 0.01351\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0153 - mean_absolute_error: 0.0997\n",
      "Epoch 20/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.0879\n",
      "Epoch 00020: loss improved from 0.01351 to 0.01232, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0123 - mean_absolute_error: 0.0879\n",
      "Epoch 21/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0894\n",
      "Epoch 00021: loss improved from 0.01232 to 0.01224, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0122 - mean_absolute_error: 0.0904\n",
      "Epoch 22/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0909\n",
      "Epoch 00022: loss did not improve from 0.01224\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0128 - mean_absolute_error: 0.0911\n",
      "Epoch 23/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0128 - mean_absolute_error: 0.0910\n",
      "Epoch 00023: loss did not improve from 0.01224\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0125 - mean_absolute_error: 0.0894\n",
      "Epoch 24/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0945\n",
      "Epoch 00024: loss did not improve from 0.01224\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0132 - mean_absolute_error: 0.0934\n",
      "Epoch 25/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0806\n",
      "Epoch 00025: loss improved from 0.01224 to 0.00952, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0095 - mean_absolute_error: 0.0798\n",
      "Epoch 26/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0831\n",
      "Epoch 00026: loss did not improve from 0.00952\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0119 - mean_absolute_error: 0.0869\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0823\n",
      "Epoch 00027: loss did not improve from 0.00952\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0107 - mean_absolute_error: 0.0823\n",
      "Epoch 28/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0110 - mean_absolute_error: 0.0851\n",
      "Epoch 00028: loss did not improve from 0.00952\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0109 - mean_absolute_error: 0.0846\n",
      "Epoch 29/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0802\n",
      "Epoch 00029: loss did not improve from 0.00952\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0099 - mean_absolute_error: 0.0813\n",
      "Epoch 30/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0809\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00952\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0098 - mean_absolute_error: 0.0796\n",
      "Epoch 31/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0724\n",
      "Epoch 00031: loss improved from 0.00952 to 0.00812, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0081 - mean_absolute_error: 0.0724\n",
      "Epoch 32/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0714\n",
      "Epoch 00032: loss improved from 0.00812 to 0.00799, saving model to pesos1.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0080 - mean_absolute_error: 0.0719\n",
      "Epoch 33/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.0762\n",
      "Epoch 00033: loss did not improve from 0.00799\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0091 - mean_absolute_error: 0.0759\n",
      "Epoch 34/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0725\n",
      "Epoch 00034: loss did not improve from 0.00799\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0084 - mean_absolute_error: 0.0732\n",
      "Epoch 35/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0728\n",
      "Epoch 00035: loss did not improve from 0.00799\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0082 - mean_absolute_error: 0.0727\n",
      "Epoch 36/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.0742\n",
      "Epoch 00036: loss did not improve from 0.00799\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0086 - mean_absolute_error: 0.0742\n",
      "Epoch 37/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.0739\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00799\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0085 - mean_absolute_error: 0.0739\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0704\n",
      "Epoch 00038: loss improved from 0.00799 to 0.00753, saving model to pesos1.h5\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0075 - mean_absolute_error: 0.0704\n",
      "Epoch 39/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0745\n",
      "Epoch 00039: loss did not improve from 0.00753\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0081 - mean_absolute_error: 0.0739\n",
      "Epoch 40/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0071 - mean_absolute_error: 0.0691\n",
      "Epoch 00040: loss improved from 0.00753 to 0.00727, saving model to pesos1.h5\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0073 - mean_absolute_error: 0.0697\n",
      "Epoch 41/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0070 - mean_absolute_error: 0.0678\n",
      "Epoch 00041: loss improved from 0.00727 to 0.00714, saving model to pesos1.h5\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0071 - mean_absolute_error: 0.0682\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0081 - mean_absolute_error: 0.0719\n",
      "Epoch 00042: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0081 - mean_absolute_error: 0.0719\n",
      "Epoch 43/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0721\n",
      "Epoch 00043: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0080 - mean_absolute_error: 0.0719\n",
      "Epoch 44/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0722\n",
      "Epoch 00044: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0083 - mean_absolute_error: 0.0725\n",
      "Epoch 45/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0690\n",
      "Epoch 00045: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0073 - mean_absolute_error: 0.0688\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0701\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0078 - mean_absolute_error: 0.0701\n",
      "Epoch 47/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0705\n",
      "Epoch 00047: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0078 - mean_absolute_error: 0.0704\n",
      "Epoch 48/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0685\n",
      "Epoch 00048: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0076 - mean_absolute_error: 0.0694\n",
      "Epoch 49/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.0752\n",
      "Epoch 00049: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0085 - mean_absolute_error: 0.0748\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0687\n",
      "Epoch 00050: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0074 - mean_absolute_error: 0.0687\n",
      "Epoch 51/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0708\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00714\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0075 - mean_absolute_error: 0.0702\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e759f2a430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regressor\n",
    "\n",
    "regressor = tf.keras.models.Sequential()\n",
    "regressor.add(tf.keras.layers.LSTM(units= 64, return_sequences = True, input_shape=(previsores.shape[1], 1)))\n",
    "regressor.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "regressor.add(tf.keras.layers.LSTM(units= 32, return_sequences = True))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "regressor.add(tf.keras.layers.LSTM(units= 32, return_sequences = True))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "regressor.add(tf.keras.layers.LSTM(units= 32))\n",
    "regressor.add(tf.keras.layers.Dropout(0.20))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['mean_absolute_error'])\n",
    "\n",
    "regressor.fit(previsores, preco_real, epochs =1000, batch_size = 32, callbacks = [es, rlr, mcp])\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(units=32, activation='tanh', input_shape=(self.state_size,)))\n",
    "#model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(lr = 0.001))\n",
    "#historico = regressor.fit(previsores, preco_real, epochs = 200, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127775],\n",
       "       [127860],\n",
       "       [127845],\n",
       "       [127840],\n",
       "       [127840],\n",
       "       [127870],\n",
       "       [127840],\n",
       "       [127890],\n",
       "       [127850],\n",
       "       [127845],\n",
       "       [127835],\n",
       "       [127870],\n",
       "       [127890],\n",
       "       [127820],\n",
       "       [127815],\n",
       "       [127825],\n",
       "       [127800],\n",
       "       [127780],\n",
       "       [127810],\n",
       "       [127795],\n",
       "       [127840],\n",
       "       [127835],\n",
       "       [127800],\n",
       "       [127785],\n",
       "       [127800],\n",
       "       [127815],\n",
       "       [127830],\n",
       "       [127830],\n",
       "       [127810],\n",
       "       [127815],\n",
       "       [127815],\n",
       "       [127760],\n",
       "       [127815],\n",
       "       [127830],\n",
       "       [127835],\n",
       "       [127815],\n",
       "       [127855],\n",
       "       [127845],\n",
       "       [127830],\n",
       "       [127890],\n",
       "       [127930],\n",
       "       [127930],\n",
       "       [127970],\n",
       "       [127945],\n",
       "       [127950],\n",
       "       [127965],\n",
       "       [127945],\n",
       "       [127930],\n",
       "       [127940],\n",
       "       [127880],\n",
       "       [127860],\n",
       "       [127870],\n",
       "       [127880],\n",
       "       [127870],\n",
       "       [127855],\n",
       "       [127840],\n",
       "       [127875],\n",
       "       [127870],\n",
       "       [127890],\n",
       "       [127870],\n",
       "       [127850],\n",
       "       [127820],\n",
       "       [127835],\n",
       "       [127845],\n",
       "       [127800],\n",
       "       [127785],\n",
       "       [127720],\n",
       "       [127735],\n",
       "       [127725],\n",
       "       [127780],\n",
       "       [127790],\n",
       "       [127805],\n",
       "       [127780],\n",
       "       [127750],\n",
       "       [127750],\n",
       "       [127795],\n",
       "       [127730],\n",
       "       [127735],\n",
       "       [127750],\n",
       "       [127810],\n",
       "       [127790],\n",
       "       [127775],\n",
       "       [127810],\n",
       "       [127780],\n",
       "       [127705],\n",
       "       [127675],\n",
       "       [127645],\n",
       "       [127620],\n",
       "       [127640],\n",
       "       [127690],\n",
       "       [127710],\n",
       "       [127690],\n",
       "       [127665],\n",
       "       [127680],\n",
       "       [127695],\n",
       "       [127700],\n",
       "       [127725],\n",
       "       [127685],\n",
       "       [127675],\n",
       "       [127690],\n",
       "       [127695],\n",
       "       [127735],\n",
       "       [127725],\n",
       "       [127635],\n",
       "       [127635],\n",
       "       [127680],\n",
       "       [127630],\n",
       "       [127630],\n",
       "       [127630],\n",
       "       [127660],\n",
       "       [127695],\n",
       "       [127760],\n",
       "       [127790],\n",
       "       [127595],\n",
       "       [127610],\n",
       "       [127665],\n",
       "       [127670],\n",
       "       [127685],\n",
       "       [127680],\n",
       "       [127660],\n",
       "       [127670],\n",
       "       [127540],\n",
       "       [127440],\n",
       "       [127435],\n",
       "       [127420],\n",
       "       [127440],\n",
       "       [127425],\n",
       "       [127405],\n",
       "       [127375],\n",
       "       [127365],\n",
       "       [127395],\n",
       "       [127390],\n",
       "       [127410],\n",
       "       [127420],\n",
       "       [127445],\n",
       "       [127445],\n",
       "       [127495],\n",
       "       [127475],\n",
       "       [127475],\n",
       "       [127495],\n",
       "       [127500],\n",
       "       [127475],\n",
       "       [127470],\n",
       "       [127470],\n",
       "       [127490],\n",
       "       [127445],\n",
       "       [127420],\n",
       "       [127380],\n",
       "       [127330],\n",
       "       [127300],\n",
       "       [127295],\n",
       "       [127330],\n",
       "       [127345],\n",
       "       [127330],\n",
       "       [127315],\n",
       "       [127325],\n",
       "       [127345],\n",
       "       [127350],\n",
       "       [127340],\n",
       "       [127350],\n",
       "       [127370],\n",
       "       [127305],\n",
       "       [127315],\n",
       "       [127320],\n",
       "       [127295],\n",
       "       [127295],\n",
       "       [127370],\n",
       "       [127380],\n",
       "       [127425],\n",
       "       [127415],\n",
       "       [127410],\n",
       "       [127395],\n",
       "       [127405],\n",
       "       [127440],\n",
       "       [127415],\n",
       "       [127435],\n",
       "       [127520],\n",
       "       [127540],\n",
       "       [127510],\n",
       "       [127560],\n",
       "       [127515],\n",
       "       [127495],\n",
       "       [127470],\n",
       "       [127460],\n",
       "       [127505],\n",
       "       [127440],\n",
       "       [127405],\n",
       "       [127430],\n",
       "       [127415],\n",
       "       [127410],\n",
       "       [127455],\n",
       "       [127475],\n",
       "       [127535],\n",
       "       [127535],\n",
       "       [127545],\n",
       "       [127490],\n",
       "       [127480],\n",
       "       [127550],\n",
       "       [127580],\n",
       "       [127575],\n",
       "       [127540],\n",
       "       [127510],\n",
       "       [127575],\n",
       "       [127580],\n",
       "       [127580],\n",
       "       [127575],\n",
       "       [127495],\n",
       "       [127520],\n",
       "       [127445],\n",
       "       [127505],\n",
       "       [127530],\n",
       "       [127415],\n",
       "       [127395],\n",
       "       [127375],\n",
       "       [127340],\n",
       "       [127310],\n",
       "       [127300],\n",
       "       [127295],\n",
       "       [127285],\n",
       "       [127270],\n",
       "       [127280],\n",
       "       [127305],\n",
       "       [127315],\n",
       "       [127320],\n",
       "       [127345],\n",
       "       [127370],\n",
       "       [127420],\n",
       "       [127465],\n",
       "       [127425],\n",
       "       [127435],\n",
       "       [127380],\n",
       "       [127325],\n",
       "       [127325],\n",
       "       [127325],\n",
       "       [127260],\n",
       "       [127240],\n",
       "       [127275],\n",
       "       [127280],\n",
       "       [127245],\n",
       "       [127205],\n",
       "       [127080],\n",
       "       [127195],\n",
       "       [127200],\n",
       "       [127195],\n",
       "       [127225],\n",
       "       [127230],\n",
       "       [127240],\n",
       "       [127230],\n",
       "       [127270],\n",
       "       [127295],\n",
       "       [127290],\n",
       "       [127290],\n",
       "       [127285],\n",
       "       [127285],\n",
       "       [127290],\n",
       "       [127285],\n",
       "       [127185],\n",
       "       [127230],\n",
       "       [127285],\n",
       "       [127320],\n",
       "       [127300],\n",
       "       [127255],\n",
       "       [127230],\n",
       "       [127315],\n",
       "       [127435],\n",
       "       [127380],\n",
       "       [127470],\n",
       "       [127495],\n",
       "       [127505],\n",
       "       [127550],\n",
       "       [127600],\n",
       "       [127600],\n",
       "       [127565],\n",
       "       [127550],\n",
       "       [127505],\n",
       "       [127535],\n",
       "       [127565],\n",
       "       [127585],\n",
       "       [127620],\n",
       "       [127570],\n",
       "       [127570],\n",
       "       [127620],\n",
       "       [127625],\n",
       "       [127615],\n",
       "       [127635],\n",
       "       [127615],\n",
       "       [127620],\n",
       "       [127530],\n",
       "       [127550],\n",
       "       [127590],\n",
       "       [127595],\n",
       "       [127590],\n",
       "       [127570],\n",
       "       [127585],\n",
       "       [127615],\n",
       "       [127655],\n",
       "       [127595],\n",
       "       [127585],\n",
       "       [127615],\n",
       "       [127610],\n",
       "       [127565],\n",
       "       [127645],\n",
       "       [127585],\n",
       "       [127540],\n",
       "       [127530],\n",
       "       [127590],\n",
       "       [127565],\n",
       "       [127525],\n",
       "       [127415],\n",
       "       [127435],\n",
       "       [127450],\n",
       "       [127440],\n",
       "       [127470],\n",
       "       [127500],\n",
       "       [127520],\n",
       "       [127540],\n",
       "       [127575],\n",
       "       [127610],\n",
       "       [127660],\n",
       "       [127730],\n",
       "       [127670],\n",
       "       [127630],\n",
       "       [127610],\n",
       "       [127495],\n",
       "       [127480],\n",
       "       [127465],\n",
       "       [127410],\n",
       "       [127425],\n",
       "       [127380],\n",
       "       [127390],\n",
       "       [127410],\n",
       "       [127450],\n",
       "       [127400],\n",
       "       [127365],\n",
       "       [127425],\n",
       "       [127500],\n",
       "       [127525],\n",
       "       [127455],\n",
       "       [127420],\n",
       "       [127520],\n",
       "       [127460],\n",
       "       [127510],\n",
       "       [127495],\n",
       "       [127390],\n",
       "       [127385],\n",
       "       [127350],\n",
       "       [127420],\n",
       "       [127425],\n",
       "       [127365],\n",
       "       [127415],\n",
       "       [127335],\n",
       "       [127315],\n",
       "       [127300],\n",
       "       [127350],\n",
       "       [127405],\n",
       "       [127355],\n",
       "       [127320],\n",
       "       [127330],\n",
       "       [127345],\n",
       "       [127250],\n",
       "       [127225]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = base_teste.drop('Data', axis =1)\n",
    "teste.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = teste.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range = (0,1))\n",
    "entradas = normalizador.fit_transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = []\n",
    "for i in range (32, 361):\n",
    "    x_teste.append(entradas[i-32:i , 0 ])\n",
    "x_teste = np.array(x_teste)\n",
    "x_teste = np.reshape(x_teste, (x_teste.shape[0], x_teste.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 32, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = regressor.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = normalizador.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = teste[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = np.concatenate([entry, previsoes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['total'] = resultado[0] - resultado[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127795.640625</td>\n",
       "      <td>19.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127830.0</td>\n",
       "      <td>127790.531250</td>\n",
       "      <td>39.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127835.0</td>\n",
       "      <td>127787.421875</td>\n",
       "      <td>47.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127787.914062</td>\n",
       "      <td>27.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127855.0</td>\n",
       "      <td>127791.578125</td>\n",
       "      <td>63.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>127845.0</td>\n",
       "      <td>127799.031250</td>\n",
       "      <td>45.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127830.0</td>\n",
       "      <td>127809.085938</td>\n",
       "      <td>20.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>127890.0</td>\n",
       "      <td>127818.117188</td>\n",
       "      <td>71.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>127930.0</td>\n",
       "      <td>127827.578125</td>\n",
       "      <td>102.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127930.0</td>\n",
       "      <td>127839.656250</td>\n",
       "      <td>90.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>127970.0</td>\n",
       "      <td>127855.218750</td>\n",
       "      <td>114.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>127945.0</td>\n",
       "      <td>127874.945312</td>\n",
       "      <td>70.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>127950.0</td>\n",
       "      <td>127895.445312</td>\n",
       "      <td>54.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>127965.0</td>\n",
       "      <td>127912.406250</td>\n",
       "      <td>52.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>127945.0</td>\n",
       "      <td>127923.132812</td>\n",
       "      <td>21.867188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0              1       total\n",
       "0   127815.0  127795.640625   19.359375\n",
       "1   127830.0  127790.531250   39.468750\n",
       "2   127835.0  127787.421875   47.578125\n",
       "3   127815.0  127787.914062   27.085938\n",
       "4   127855.0  127791.578125   63.421875\n",
       "5   127845.0  127799.031250   45.968750\n",
       "6   127830.0  127809.085938   20.914062\n",
       "7   127890.0  127818.117188   71.882812\n",
       "8   127930.0  127827.578125  102.421875\n",
       "9   127930.0  127839.656250   90.343750\n",
       "10  127970.0  127855.218750  114.781250\n",
       "11  127945.0  127874.945312   70.054688\n",
       "12  127950.0  127895.445312   54.554688\n",
       "13  127965.0  127912.406250   52.593750\n",
       "14  127945.0  127923.132812   21.867188"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste2 = pd.read_csv('./data-projects/mini_inidice_novo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste2.drop('Abertura', axis=1, inplace = True)\n",
    "base_teste2.drop('MÃ­nima', axis=1, inplace = True)\n",
    "base_teste2.drop('MÃ¡xima', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>128465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>128435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>128425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>127895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>127950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>127940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>128010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>128105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data  Fechamento\n",
       "0     2021-07-12      128465\n",
       "1     2021-07-12      128435\n",
       "2     2021-07-12      128410\n",
       "3     2021-07-12      128410\n",
       "4     2021-07-12      128425\n",
       "...          ...         ...\n",
       "4994  2021-06-28      127895\n",
       "4995  2021-06-28      127950\n",
       "4996  2021-06-28      127940\n",
       "4997  2021-06-28      128010\n",
       "4998  2021-06-28      128105\n",
       "\n",
       "[4999 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_teste2 = base_teste.drop('Data', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste2 = base_teste2[:367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>127320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>127330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>127345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>127250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>127225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fechamento\n",
       "0        127775\n",
       "1        127860\n",
       "2        127845\n",
       "3        127840\n",
       "4        127840\n",
       "..          ...\n",
       "356      127320\n",
       "357      127330\n",
       "358      127345\n",
       "359      127250\n",
       "360      127225\n",
       "\n",
       "[361 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127775],\n",
       "       [127860],\n",
       "       [127845],\n",
       "       [127840],\n",
       "       [127840],\n",
       "       [127870],\n",
       "       [127840],\n",
       "       [127890],\n",
       "       [127850],\n",
       "       [127845],\n",
       "       [127835],\n",
       "       [127870],\n",
       "       [127890],\n",
       "       [127820],\n",
       "       [127815],\n",
       "       [127825],\n",
       "       [127800],\n",
       "       [127780],\n",
       "       [127810],\n",
       "       [127795],\n",
       "       [127840],\n",
       "       [127835],\n",
       "       [127800],\n",
       "       [127785],\n",
       "       [127800],\n",
       "       [127815],\n",
       "       [127830],\n",
       "       [127830],\n",
       "       [127810],\n",
       "       [127815],\n",
       "       [127815],\n",
       "       [127760],\n",
       "       [127815],\n",
       "       [127830],\n",
       "       [127835],\n",
       "       [127815],\n",
       "       [127855],\n",
       "       [127845],\n",
       "       [127830],\n",
       "       [127890],\n",
       "       [127930],\n",
       "       [127930],\n",
       "       [127970],\n",
       "       [127945],\n",
       "       [127950],\n",
       "       [127965],\n",
       "       [127945],\n",
       "       [127930],\n",
       "       [127940],\n",
       "       [127880],\n",
       "       [127860],\n",
       "       [127870],\n",
       "       [127880],\n",
       "       [127870],\n",
       "       [127855],\n",
       "       [127840],\n",
       "       [127875],\n",
       "       [127870],\n",
       "       [127890],\n",
       "       [127870],\n",
       "       [127850],\n",
       "       [127820],\n",
       "       [127835],\n",
       "       [127845],\n",
       "       [127800],\n",
       "       [127785],\n",
       "       [127720],\n",
       "       [127735],\n",
       "       [127725],\n",
       "       [127780],\n",
       "       [127790],\n",
       "       [127805],\n",
       "       [127780],\n",
       "       [127750],\n",
       "       [127750],\n",
       "       [127795],\n",
       "       [127730],\n",
       "       [127735],\n",
       "       [127750],\n",
       "       [127810],\n",
       "       [127790],\n",
       "       [127775],\n",
       "       [127810],\n",
       "       [127780],\n",
       "       [127705],\n",
       "       [127675],\n",
       "       [127645],\n",
       "       [127620],\n",
       "       [127640],\n",
       "       [127690],\n",
       "       [127710],\n",
       "       [127690],\n",
       "       [127665],\n",
       "       [127680],\n",
       "       [127695],\n",
       "       [127700],\n",
       "       [127725],\n",
       "       [127685],\n",
       "       [127675],\n",
       "       [127690],\n",
       "       [127695],\n",
       "       [127735],\n",
       "       [127725],\n",
       "       [127635],\n",
       "       [127635],\n",
       "       [127680],\n",
       "       [127630],\n",
       "       [127630],\n",
       "       [127630],\n",
       "       [127660],\n",
       "       [127695],\n",
       "       [127760],\n",
       "       [127790],\n",
       "       [127595],\n",
       "       [127610],\n",
       "       [127665],\n",
       "       [127670],\n",
       "       [127685],\n",
       "       [127680],\n",
       "       [127660],\n",
       "       [127670],\n",
       "       [127540],\n",
       "       [127440],\n",
       "       [127435],\n",
       "       [127420],\n",
       "       [127440],\n",
       "       [127425],\n",
       "       [127405],\n",
       "       [127375],\n",
       "       [127365],\n",
       "       [127395],\n",
       "       [127390],\n",
       "       [127410],\n",
       "       [127420],\n",
       "       [127445],\n",
       "       [127445],\n",
       "       [127495],\n",
       "       [127475],\n",
       "       [127475],\n",
       "       [127495],\n",
       "       [127500],\n",
       "       [127475],\n",
       "       [127470],\n",
       "       [127470],\n",
       "       [127490],\n",
       "       [127445],\n",
       "       [127420],\n",
       "       [127380],\n",
       "       [127330],\n",
       "       [127300],\n",
       "       [127295],\n",
       "       [127330],\n",
       "       [127345],\n",
       "       [127330],\n",
       "       [127315],\n",
       "       [127325],\n",
       "       [127345],\n",
       "       [127350],\n",
       "       [127340],\n",
       "       [127350],\n",
       "       [127370],\n",
       "       [127305],\n",
       "       [127315],\n",
       "       [127320],\n",
       "       [127295],\n",
       "       [127295],\n",
       "       [127370],\n",
       "       [127380],\n",
       "       [127425],\n",
       "       [127415],\n",
       "       [127410],\n",
       "       [127395],\n",
       "       [127405],\n",
       "       [127440],\n",
       "       [127415],\n",
       "       [127435],\n",
       "       [127520],\n",
       "       [127540],\n",
       "       [127510],\n",
       "       [127560],\n",
       "       [127515],\n",
       "       [127495],\n",
       "       [127470],\n",
       "       [127460],\n",
       "       [127505],\n",
       "       [127440],\n",
       "       [127405],\n",
       "       [127430],\n",
       "       [127415],\n",
       "       [127410],\n",
       "       [127455],\n",
       "       [127475],\n",
       "       [127535],\n",
       "       [127535],\n",
       "       [127545],\n",
       "       [127490],\n",
       "       [127480],\n",
       "       [127550],\n",
       "       [127580],\n",
       "       [127575],\n",
       "       [127540],\n",
       "       [127510],\n",
       "       [127575],\n",
       "       [127580],\n",
       "       [127580],\n",
       "       [127575],\n",
       "       [127495],\n",
       "       [127520],\n",
       "       [127445],\n",
       "       [127505],\n",
       "       [127530],\n",
       "       [127415],\n",
       "       [127395],\n",
       "       [127375],\n",
       "       [127340],\n",
       "       [127310],\n",
       "       [127300],\n",
       "       [127295],\n",
       "       [127285],\n",
       "       [127270],\n",
       "       [127280],\n",
       "       [127305],\n",
       "       [127315],\n",
       "       [127320],\n",
       "       [127345],\n",
       "       [127370],\n",
       "       [127420],\n",
       "       [127465],\n",
       "       [127425],\n",
       "       [127435],\n",
       "       [127380],\n",
       "       [127325],\n",
       "       [127325],\n",
       "       [127325],\n",
       "       [127260],\n",
       "       [127240],\n",
       "       [127275],\n",
       "       [127280],\n",
       "       [127245],\n",
       "       [127205],\n",
       "       [127080],\n",
       "       [127195],\n",
       "       [127200],\n",
       "       [127195],\n",
       "       [127225],\n",
       "       [127230],\n",
       "       [127240],\n",
       "       [127230],\n",
       "       [127270],\n",
       "       [127295],\n",
       "       [127290],\n",
       "       [127290],\n",
       "       [127285],\n",
       "       [127285],\n",
       "       [127290],\n",
       "       [127285],\n",
       "       [127185],\n",
       "       [127230],\n",
       "       [127285],\n",
       "       [127320],\n",
       "       [127300],\n",
       "       [127255],\n",
       "       [127230],\n",
       "       [127315],\n",
       "       [127435],\n",
       "       [127380],\n",
       "       [127470],\n",
       "       [127495],\n",
       "       [127505],\n",
       "       [127550],\n",
       "       [127600],\n",
       "       [127600],\n",
       "       [127565],\n",
       "       [127550],\n",
       "       [127505],\n",
       "       [127535],\n",
       "       [127565],\n",
       "       [127585],\n",
       "       [127620],\n",
       "       [127570],\n",
       "       [127570],\n",
       "       [127620],\n",
       "       [127625],\n",
       "       [127615],\n",
       "       [127635],\n",
       "       [127615],\n",
       "       [127620],\n",
       "       [127530],\n",
       "       [127550],\n",
       "       [127590],\n",
       "       [127595],\n",
       "       [127590],\n",
       "       [127570],\n",
       "       [127585],\n",
       "       [127615],\n",
       "       [127655],\n",
       "       [127595],\n",
       "       [127585],\n",
       "       [127615],\n",
       "       [127610],\n",
       "       [127565],\n",
       "       [127645],\n",
       "       [127585],\n",
       "       [127540],\n",
       "       [127530],\n",
       "       [127590],\n",
       "       [127565],\n",
       "       [127525],\n",
       "       [127415],\n",
       "       [127435],\n",
       "       [127450],\n",
       "       [127440],\n",
       "       [127470],\n",
       "       [127500],\n",
       "       [127520],\n",
       "       [127540],\n",
       "       [127575],\n",
       "       [127610],\n",
       "       [127660],\n",
       "       [127730],\n",
       "       [127670],\n",
       "       [127630],\n",
       "       [127610],\n",
       "       [127495],\n",
       "       [127480],\n",
       "       [127465],\n",
       "       [127410],\n",
       "       [127425],\n",
       "       [127380],\n",
       "       [127390],\n",
       "       [127410],\n",
       "       [127450],\n",
       "       [127400],\n",
       "       [127365],\n",
       "       [127425],\n",
       "       [127500],\n",
       "       [127525],\n",
       "       [127455],\n",
       "       [127420],\n",
       "       [127520],\n",
       "       [127460],\n",
       "       [127510],\n",
       "       [127495],\n",
       "       [127390],\n",
       "       [127385],\n",
       "       [127350],\n",
       "       [127420],\n",
       "       [127425],\n",
       "       [127365],\n",
       "       [127415],\n",
       "       [127335],\n",
       "       [127315],\n",
       "       [127300],\n",
       "       [127350],\n",
       "       [127405],\n",
       "       [127355],\n",
       "       [127320],\n",
       "       [127330],\n",
       "       [127345],\n",
       "       [127250],\n",
       "       [127225]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_atual = base_teste2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range = (0,1))\n",
    "base_atual = normalizador.fit_transform(base_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78089888],\n",
       "       [0.87640449],\n",
       "       [0.85955056],\n",
       "       [0.85393258],\n",
       "       [0.85393258],\n",
       "       [0.88764045],\n",
       "       [0.85393258],\n",
       "       [0.91011236],\n",
       "       [0.86516854],\n",
       "       [0.85955056],\n",
       "       [0.84831461],\n",
       "       [0.88764045],\n",
       "       [0.91011236],\n",
       "       [0.83146067],\n",
       "       [0.8258427 ],\n",
       "       [0.83707865],\n",
       "       [0.80898876],\n",
       "       [0.78651685],\n",
       "       [0.82022472],\n",
       "       [0.80337079],\n",
       "       [0.85393258],\n",
       "       [0.84831461],\n",
       "       [0.80898876],\n",
       "       [0.79213483],\n",
       "       [0.80898876],\n",
       "       [0.8258427 ],\n",
       "       [0.84269663],\n",
       "       [0.84269663],\n",
       "       [0.82022472],\n",
       "       [0.8258427 ],\n",
       "       [0.8258427 ],\n",
       "       [0.76404494],\n",
       "       [0.8258427 ],\n",
       "       [0.84269663],\n",
       "       [0.84831461],\n",
       "       [0.8258427 ],\n",
       "       [0.87078652],\n",
       "       [0.85955056],\n",
       "       [0.84269663],\n",
       "       [0.91011236],\n",
       "       [0.95505618],\n",
       "       [0.95505618],\n",
       "       [1.        ],\n",
       "       [0.97191011],\n",
       "       [0.97752809],\n",
       "       [0.99438202],\n",
       "       [0.97191011],\n",
       "       [0.95505618],\n",
       "       [0.96629213],\n",
       "       [0.8988764 ],\n",
       "       [0.87640449],\n",
       "       [0.88764045],\n",
       "       [0.8988764 ],\n",
       "       [0.88764045],\n",
       "       [0.87078652],\n",
       "       [0.85393258],\n",
       "       [0.89325843],\n",
       "       [0.88764045],\n",
       "       [0.91011236],\n",
       "       [0.88764045],\n",
       "       [0.86516854],\n",
       "       [0.83146067],\n",
       "       [0.84831461],\n",
       "       [0.85955056],\n",
       "       [0.80898876],\n",
       "       [0.79213483],\n",
       "       [0.71910112],\n",
       "       [0.73595506],\n",
       "       [0.7247191 ],\n",
       "       [0.78651685],\n",
       "       [0.79775281],\n",
       "       [0.81460674],\n",
       "       [0.78651685],\n",
       "       [0.75280899],\n",
       "       [0.75280899],\n",
       "       [0.80337079],\n",
       "       [0.73033708],\n",
       "       [0.73595506],\n",
       "       [0.75280899],\n",
       "       [0.82022472],\n",
       "       [0.79775281],\n",
       "       [0.78089888],\n",
       "       [0.82022472],\n",
       "       [0.78651685],\n",
       "       [0.70224719],\n",
       "       [0.66853933],\n",
       "       [0.63483146],\n",
       "       [0.60674157],\n",
       "       [0.62921348],\n",
       "       [0.68539326],\n",
       "       [0.70786517],\n",
       "       [0.68539326],\n",
       "       [0.65730337],\n",
       "       [0.6741573 ],\n",
       "       [0.69101124],\n",
       "       [0.69662921],\n",
       "       [0.7247191 ],\n",
       "       [0.67977528],\n",
       "       [0.66853933],\n",
       "       [0.68539326],\n",
       "       [0.69101124],\n",
       "       [0.73595506],\n",
       "       [0.7247191 ],\n",
       "       [0.62359551],\n",
       "       [0.62359551],\n",
       "       [0.6741573 ],\n",
       "       [0.61797753],\n",
       "       [0.61797753],\n",
       "       [0.61797753],\n",
       "       [0.65168539],\n",
       "       [0.69101124],\n",
       "       [0.76404494],\n",
       "       [0.79775281],\n",
       "       [0.57865169],\n",
       "       [0.59550562],\n",
       "       [0.65730337],\n",
       "       [0.66292135],\n",
       "       [0.67977528],\n",
       "       [0.6741573 ],\n",
       "       [0.65168539],\n",
       "       [0.66292135],\n",
       "       [0.51685393],\n",
       "       [0.40449438],\n",
       "       [0.3988764 ],\n",
       "       [0.38202247],\n",
       "       [0.40449438],\n",
       "       [0.38764045],\n",
       "       [0.36516854],\n",
       "       [0.33146067],\n",
       "       [0.32022472],\n",
       "       [0.35393258],\n",
       "       [0.34831461],\n",
       "       [0.37078652],\n",
       "       [0.38202247],\n",
       "       [0.41011236],\n",
       "       [0.41011236],\n",
       "       [0.46629213],\n",
       "       [0.44382022],\n",
       "       [0.44382022],\n",
       "       [0.46629213],\n",
       "       [0.47191011],\n",
       "       [0.44382022],\n",
       "       [0.43820225],\n",
       "       [0.43820225],\n",
       "       [0.46067416],\n",
       "       [0.41011236],\n",
       "       [0.38202247],\n",
       "       [0.33707865],\n",
       "       [0.28089888],\n",
       "       [0.24719101],\n",
       "       [0.24157303],\n",
       "       [0.28089888],\n",
       "       [0.29775281],\n",
       "       [0.28089888],\n",
       "       [0.26404494],\n",
       "       [0.2752809 ],\n",
       "       [0.29775281],\n",
       "       [0.30337079],\n",
       "       [0.29213483],\n",
       "       [0.30337079],\n",
       "       [0.3258427 ],\n",
       "       [0.25280899],\n",
       "       [0.26404494],\n",
       "       [0.26966292],\n",
       "       [0.24157303],\n",
       "       [0.24157303],\n",
       "       [0.3258427 ],\n",
       "       [0.33707865],\n",
       "       [0.38764045],\n",
       "       [0.37640449],\n",
       "       [0.37078652],\n",
       "       [0.35393258],\n",
       "       [0.36516854],\n",
       "       [0.40449438],\n",
       "       [0.37640449],\n",
       "       [0.3988764 ],\n",
       "       [0.49438202],\n",
       "       [0.51685393],\n",
       "       [0.48314607],\n",
       "       [0.53932584],\n",
       "       [0.48876404],\n",
       "       [0.46629213],\n",
       "       [0.43820225],\n",
       "       [0.42696629],\n",
       "       [0.47752809],\n",
       "       [0.40449438],\n",
       "       [0.36516854],\n",
       "       [0.39325843],\n",
       "       [0.37640449],\n",
       "       [0.37078652],\n",
       "       [0.42134831],\n",
       "       [0.44382022],\n",
       "       [0.51123596],\n",
       "       [0.51123596],\n",
       "       [0.52247191],\n",
       "       [0.46067416],\n",
       "       [0.4494382 ],\n",
       "       [0.52808989],\n",
       "       [0.56179775],\n",
       "       [0.55617978],\n",
       "       [0.51685393],\n",
       "       [0.48314607],\n",
       "       [0.55617978],\n",
       "       [0.56179775],\n",
       "       [0.56179775],\n",
       "       [0.55617978],\n",
       "       [0.46629213],\n",
       "       [0.49438202],\n",
       "       [0.41011236],\n",
       "       [0.47752809],\n",
       "       [0.50561798],\n",
       "       [0.37640449],\n",
       "       [0.35393258],\n",
       "       [0.33146067],\n",
       "       [0.29213483],\n",
       "       [0.25842697],\n",
       "       [0.24719101],\n",
       "       [0.24157303],\n",
       "       [0.23033708],\n",
       "       [0.21348315],\n",
       "       [0.2247191 ],\n",
       "       [0.25280899],\n",
       "       [0.26404494],\n",
       "       [0.26966292],\n",
       "       [0.29775281],\n",
       "       [0.3258427 ],\n",
       "       [0.38202247],\n",
       "       [0.43258427],\n",
       "       [0.38764045],\n",
       "       [0.3988764 ],\n",
       "       [0.33707865],\n",
       "       [0.2752809 ],\n",
       "       [0.2752809 ],\n",
       "       [0.2752809 ],\n",
       "       [0.20224719],\n",
       "       [0.17977528],\n",
       "       [0.21910112],\n",
       "       [0.2247191 ],\n",
       "       [0.18539326],\n",
       "       [0.14044944],\n",
       "       [0.        ],\n",
       "       [0.12921348],\n",
       "       [0.13483146],\n",
       "       [0.12921348],\n",
       "       [0.16292135],\n",
       "       [0.16853933],\n",
       "       [0.17977528],\n",
       "       [0.16853933],\n",
       "       [0.21348315],\n",
       "       [0.24157303],\n",
       "       [0.23595506],\n",
       "       [0.23595506],\n",
       "       [0.23033708],\n",
       "       [0.23033708],\n",
       "       [0.23595506],\n",
       "       [0.23033708],\n",
       "       [0.11797753],\n",
       "       [0.16853933],\n",
       "       [0.23033708],\n",
       "       [0.26966292],\n",
       "       [0.24719101],\n",
       "       [0.19662921],\n",
       "       [0.16853933],\n",
       "       [0.26404494],\n",
       "       [0.3988764 ],\n",
       "       [0.33707865],\n",
       "       [0.43820225],\n",
       "       [0.46629213],\n",
       "       [0.47752809],\n",
       "       [0.52808989],\n",
       "       [0.58426966],\n",
       "       [0.58426966],\n",
       "       [0.54494382],\n",
       "       [0.52808989],\n",
       "       [0.47752809],\n",
       "       [0.51123596],\n",
       "       [0.54494382],\n",
       "       [0.56741573],\n",
       "       [0.60674157],\n",
       "       [0.5505618 ],\n",
       "       [0.5505618 ],\n",
       "       [0.60674157],\n",
       "       [0.61235955],\n",
       "       [0.6011236 ],\n",
       "       [0.62359551],\n",
       "       [0.6011236 ],\n",
       "       [0.60674157],\n",
       "       [0.50561798],\n",
       "       [0.52808989],\n",
       "       [0.57303371],\n",
       "       [0.57865169],\n",
       "       [0.57303371],\n",
       "       [0.5505618 ],\n",
       "       [0.56741573],\n",
       "       [0.6011236 ],\n",
       "       [0.64606742],\n",
       "       [0.57865169],\n",
       "       [0.56741573],\n",
       "       [0.6011236 ],\n",
       "       [0.59550562],\n",
       "       [0.54494382],\n",
       "       [0.63483146],\n",
       "       [0.56741573],\n",
       "       [0.51685393],\n",
       "       [0.50561798],\n",
       "       [0.57303371],\n",
       "       [0.54494382],\n",
       "       [0.5       ],\n",
       "       [0.37640449],\n",
       "       [0.3988764 ],\n",
       "       [0.41573034],\n",
       "       [0.40449438],\n",
       "       [0.43820225],\n",
       "       [0.47191011],\n",
       "       [0.49438202],\n",
       "       [0.51685393],\n",
       "       [0.55617978],\n",
       "       [0.59550562],\n",
       "       [0.65168539],\n",
       "       [0.73033708],\n",
       "       [0.66292135],\n",
       "       [0.61797753],\n",
       "       [0.59550562],\n",
       "       [0.46629213],\n",
       "       [0.4494382 ],\n",
       "       [0.43258427],\n",
       "       [0.37078652],\n",
       "       [0.38764045],\n",
       "       [0.33707865],\n",
       "       [0.34831461],\n",
       "       [0.37078652],\n",
       "       [0.41573034],\n",
       "       [0.35955056],\n",
       "       [0.32022472],\n",
       "       [0.38764045],\n",
       "       [0.47191011],\n",
       "       [0.5       ],\n",
       "       [0.42134831],\n",
       "       [0.38202247],\n",
       "       [0.49438202],\n",
       "       [0.42696629],\n",
       "       [0.48314607],\n",
       "       [0.46629213],\n",
       "       [0.34831461],\n",
       "       [0.34269663],\n",
       "       [0.30337079],\n",
       "       [0.38202247],\n",
       "       [0.38764045],\n",
       "       [0.32022472],\n",
       "       [0.37640449],\n",
       "       [0.28651685],\n",
       "       [0.26404494],\n",
       "       [0.24719101],\n",
       "       [0.30337079],\n",
       "       [0.36516854],\n",
       "       [0.30898876],\n",
       "       [0.26966292],\n",
       "       [0.28089888],\n",
       "       [0.29775281],\n",
       "       [0.19101124],\n",
       "       [0.16292135]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste = []\n",
    "for i in range (32, 361):\n",
    "    y_teste.append(entradas[i-32:i , 0 ])\n",
    "y_teste = np.array(y_teste)\n",
    "y_teste = np.reshape(y_teste, (y_teste.shape[0], y_teste.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 32, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes2 = regressor.predict(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes2 = normalizador.inverse_transform(previsoes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry2 = base_atual[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado2 = np.concatenate([entry, previsoes2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado2 = pd.DataFrame(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127795.640625</td>\n",
       "      <td>19.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127830.0</td>\n",
       "      <td>127790.531250</td>\n",
       "      <td>39.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127835.0</td>\n",
       "      <td>127787.421875</td>\n",
       "      <td>47.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127787.914062</td>\n",
       "      <td>27.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127855.0</td>\n",
       "      <td>127791.578125</td>\n",
       "      <td>63.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>127320.0</td>\n",
       "      <td>127355.070312</td>\n",
       "      <td>-35.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>127330.0</td>\n",
       "      <td>127354.210938</td>\n",
       "      <td>-24.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>127345.0</td>\n",
       "      <td>127353.695312</td>\n",
       "      <td>-8.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>127250.0</td>\n",
       "      <td>127352.976562</td>\n",
       "      <td>-102.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>127225.0</td>\n",
       "      <td>127348.953125</td>\n",
       "      <td>-123.953125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0              1       total\n",
       "0    127815.0  127795.640625   19.359375\n",
       "1    127830.0  127790.531250   39.468750\n",
       "2    127835.0  127787.421875   47.578125\n",
       "3    127815.0  127787.914062   27.085938\n",
       "4    127855.0  127791.578125   63.421875\n",
       "..        ...            ...         ...\n",
       "324  127320.0  127355.070312  -35.070312\n",
       "325  127330.0  127354.210938  -24.210938\n",
       "326  127345.0  127353.695312   -8.695312\n",
       "327  127250.0  127352.976562 -102.976562\n",
       "328  127225.0  127348.953125 -123.953125\n",
       "\n",
       "[329 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resultado2['Total'] = resultado[0] - resultado[1]\n",
    "resultado2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado2['total'] = resultado2[0] - resultado2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127795.640625</td>\n",
       "      <td>19.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127830.0</td>\n",
       "      <td>127790.531250</td>\n",
       "      <td>39.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127835.0</td>\n",
       "      <td>127787.421875</td>\n",
       "      <td>47.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127815.0</td>\n",
       "      <td>127787.914062</td>\n",
       "      <td>27.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127855.0</td>\n",
       "      <td>127791.578125</td>\n",
       "      <td>63.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>127845.0</td>\n",
       "      <td>127799.031250</td>\n",
       "      <td>45.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127830.0</td>\n",
       "      <td>127809.085938</td>\n",
       "      <td>20.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>127890.0</td>\n",
       "      <td>127818.117188</td>\n",
       "      <td>71.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>127930.0</td>\n",
       "      <td>127827.578125</td>\n",
       "      <td>102.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127930.0</td>\n",
       "      <td>127839.656250</td>\n",
       "      <td>90.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>127970.0</td>\n",
       "      <td>127855.218750</td>\n",
       "      <td>114.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>127945.0</td>\n",
       "      <td>127874.945312</td>\n",
       "      <td>70.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>127950.0</td>\n",
       "      <td>127895.445312</td>\n",
       "      <td>54.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>127965.0</td>\n",
       "      <td>127912.406250</td>\n",
       "      <td>52.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>127945.0</td>\n",
       "      <td>127923.132812</td>\n",
       "      <td>21.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>127930.0</td>\n",
       "      <td>127926.484375</td>\n",
       "      <td>3.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>127940.0</td>\n",
       "      <td>127922.359375</td>\n",
       "      <td>17.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>127880.0</td>\n",
       "      <td>127913.164062</td>\n",
       "      <td>-33.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>127860.0</td>\n",
       "      <td>127899.164062</td>\n",
       "      <td>-39.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>127870.0</td>\n",
       "      <td>127881.601562</td>\n",
       "      <td>-11.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>127880.0</td>\n",
       "      <td>127863.328125</td>\n",
       "      <td>16.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>127870.0</td>\n",
       "      <td>127848.929688</td>\n",
       "      <td>21.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>127855.0</td>\n",
       "      <td>127840.492188</td>\n",
       "      <td>14.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>127840.0</td>\n",
       "      <td>127837.726562</td>\n",
       "      <td>2.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>127875.0</td>\n",
       "      <td>127838.484375</td>\n",
       "      <td>36.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>127870.0</td>\n",
       "      <td>127842.468750</td>\n",
       "      <td>27.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127890.0</td>\n",
       "      <td>127848.273438</td>\n",
       "      <td>41.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>127870.0</td>\n",
       "      <td>127855.492188</td>\n",
       "      <td>14.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>127850.0</td>\n",
       "      <td>127861.804688</td>\n",
       "      <td>-11.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>127820.0</td>\n",
       "      <td>127864.085938</td>\n",
       "      <td>-44.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>127835.0</td>\n",
       "      <td>127859.539062</td>\n",
       "      <td>-24.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>127845.0</td>\n",
       "      <td>127848.843750</td>\n",
       "      <td>-3.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>127800.0</td>\n",
       "      <td>127835.046875</td>\n",
       "      <td>-35.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>127785.0</td>\n",
       "      <td>127820.437500</td>\n",
       "      <td>-35.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>127720.0</td>\n",
       "      <td>127805.648438</td>\n",
       "      <td>-85.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>127735.0</td>\n",
       "      <td>127788.523438</td>\n",
       "      <td>-53.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>127725.0</td>\n",
       "      <td>127769.406250</td>\n",
       "      <td>-44.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>127780.0</td>\n",
       "      <td>127750.390625</td>\n",
       "      <td>29.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>127790.0</td>\n",
       "      <td>127736.171875</td>\n",
       "      <td>53.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>127805.0</td>\n",
       "      <td>127731.062500</td>\n",
       "      <td>73.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127780.0</td>\n",
       "      <td>127737.804688</td>\n",
       "      <td>42.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>127750.0</td>\n",
       "      <td>127752.945312</td>\n",
       "      <td>-2.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>127750.0</td>\n",
       "      <td>127768.625000</td>\n",
       "      <td>-18.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>127795.0</td>\n",
       "      <td>127778.640625</td>\n",
       "      <td>16.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>127730.0</td>\n",
       "      <td>127781.828125</td>\n",
       "      <td>-51.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>127735.0</td>\n",
       "      <td>127776.773438</td>\n",
       "      <td>-41.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>127750.0</td>\n",
       "      <td>127764.835938</td>\n",
       "      <td>-14.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>127810.0</td>\n",
       "      <td>127749.585938</td>\n",
       "      <td>60.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>127790.0</td>\n",
       "      <td>127738.210938</td>\n",
       "      <td>51.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>127775.0</td>\n",
       "      <td>127734.812500</td>\n",
       "      <td>40.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0              1       total\n",
       "0   127815.0  127795.640625   19.359375\n",
       "1   127830.0  127790.531250   39.468750\n",
       "2   127835.0  127787.421875   47.578125\n",
       "3   127815.0  127787.914062   27.085938\n",
       "4   127855.0  127791.578125   63.421875\n",
       "5   127845.0  127799.031250   45.968750\n",
       "6   127830.0  127809.085938   20.914062\n",
       "7   127890.0  127818.117188   71.882812\n",
       "8   127930.0  127827.578125  102.421875\n",
       "9   127930.0  127839.656250   90.343750\n",
       "10  127970.0  127855.218750  114.781250\n",
       "11  127945.0  127874.945312   70.054688\n",
       "12  127950.0  127895.445312   54.554688\n",
       "13  127965.0  127912.406250   52.593750\n",
       "14  127945.0  127923.132812   21.867188\n",
       "15  127930.0  127926.484375    3.515625\n",
       "16  127940.0  127922.359375   17.640625\n",
       "17  127880.0  127913.164062  -33.164062\n",
       "18  127860.0  127899.164062  -39.164062\n",
       "19  127870.0  127881.601562  -11.601562\n",
       "20  127880.0  127863.328125   16.671875\n",
       "21  127870.0  127848.929688   21.070312\n",
       "22  127855.0  127840.492188   14.507812\n",
       "23  127840.0  127837.726562    2.273438\n",
       "24  127875.0  127838.484375   36.515625\n",
       "25  127870.0  127842.468750   27.531250\n",
       "26  127890.0  127848.273438   41.726562\n",
       "27  127870.0  127855.492188   14.507812\n",
       "28  127850.0  127861.804688  -11.804688\n",
       "29  127820.0  127864.085938  -44.085938\n",
       "30  127835.0  127859.539062  -24.539062\n",
       "31  127845.0  127848.843750   -3.843750\n",
       "32  127800.0  127835.046875  -35.046875\n",
       "33  127785.0  127820.437500  -35.437500\n",
       "34  127720.0  127805.648438  -85.648438\n",
       "35  127735.0  127788.523438  -53.523438\n",
       "36  127725.0  127769.406250  -44.406250\n",
       "37  127780.0  127750.390625   29.609375\n",
       "38  127790.0  127736.171875   53.828125\n",
       "39  127805.0  127731.062500   73.937500\n",
       "40  127780.0  127737.804688   42.195312\n",
       "41  127750.0  127752.945312   -2.945312\n",
       "42  127750.0  127768.625000  -18.625000\n",
       "43  127795.0  127778.640625   16.359375\n",
       "44  127730.0  127781.828125  -51.828125\n",
       "45  127735.0  127776.773438  -41.773438\n",
       "46  127750.0  127764.835938  -14.835938\n",
       "47  127810.0  127749.585938   60.414062\n",
       "48  127790.0  127738.210938   51.789062\n",
       "49  127775.0  127734.812500   40.187500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(resultado2['total'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuiÃ§Ã£o dessa regressÃ£o e quando alcancar 2 desvios padrÃ£o entrar contra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
